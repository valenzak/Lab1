{
 "metadata": {
  "name": "3before work.ipynb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1) Join the table to the shapefile, which adds county names to each census tract.  At first, I was going to write out about 50 elifs, but I asked Prof. Bergmann, who recommended a join would be more efficient (Duh).  I got halfway through writing my elifs, so this step, along with the initial setup of everything, took half an hour or so. Less than 10 minutes after Bergmann recommended joining."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##Join county names to census tracts via FIPS and FP fields\n",
      "\n",
      "#import environments\n",
      "from arcpy import env\n",
      "arcpy.env.workspace = \"C:\\\\Users\\\\Valenter\\\\Documents\\\\GitHub\\\\Lab1\\\\outputs\" #Direct to the workspace folder\n",
      "\n",
      "#define in dataset - the one to be modified\n",
      "in_data = \"saep_bg10\"\n",
      "#define in field\n",
      "in_field = \"COUNTYFP10\"\n",
      "#define table to join to the in dataset\n",
      "join_table = \"WashingtonFIPS\"\n",
      "#define field with values that correlate with those on the in field\n",
      "join_field = \"FIPSCounty\"\n",
      "\n",
      "#execture join\n",
      "arcpy.JoinField_management(in_data, in_field, join_table, join_field)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "2) I found the proper tool, Statistics_analysis, fairly quickly, but I could not get the syntax right for the life of me.  Heaven forbid there aren't two [[]] around \"POP2013\", \"SUM\"...  Anyways, by looking for examples online, I noticed that all of them did this. This problem solving took half an hour, tops."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##Sum POP2013 for each CountyName into a new table called top10\n",
      "\n",
      "#import environments\n",
      "import arcpy\n",
      "from arcpy import env\n",
      "arcpy.env.workspace = \"C:\\\\Users\\\\Valenter\\\\Documents\\\\GitHub\\\\Lab1\\\\outputs\"\n",
      "\n",
      "#define in table\n",
      "in_table = \"saep_bg10\"\n",
      "#define out table and file location\n",
      "out_table = \"C:\\\\Users\\\\Valenter\\\\Documents\\\\GitHub\\\\Lab1\\\\outputs\\\\top10\"\n",
      "#define field with values -1- to undergo the statistics operation -2-\n",
      "statistics_field = [[\"POP2013\", \"SUM\"]]\n",
      "#define a field for which to group like values for the statistical operation on the statistics_field\n",
      "case_field = [\"CountyName\"]\n",
      "\n",
      "#execute statistics analysis\n",
      "List = arcpy.Statistics_analysis(in_table, out_table, statistics_field, case_field)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "3) Split the original saep_bg10 into many shape files, based on county name.  I started by finding the Split tool in the toolbox, and making sure it was the right tool.  I then typed arcpy.split, and was able to pick the right tool from the autocorrect.  This did not take a long time; I basically just double-checked what the split tool did, and then applied it.  It worked the first time."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##Split saep_bg10 into seperate shapefiles for each county name\n",
      "\n",
      "#Import environments\n",
      "import arcpy\n",
      "from arcpy import env\n",
      "arcpy.env.workspace = \"C:\\\\Users\\\\Valenter\\\\Documents\\\\GitHub\\\\Lab1\\\\outputs\"\n",
      "\n",
      "#Define input dataset to be split\n",
      "in_feature = \"saep_bg10\"\n",
      "#Define dataset to do the splitting\n",
      "split_feature = \"saep_bg10\"\n",
      "#Define field with actual split values\n",
      "split_field = \"CountyName\"\n",
      "#Define the folder to send the results of the splits\n",
      "out_workspace = \"C:\\\\Users\\\\Valenter\\\\Documents\\\\GitHub\\\\Lab1\\\\outputs\"\n",
      "\n",
      "#Execute split\n",
      "arcpy.Split_analysis(in_feature, split_feature, split_field, out_workspace)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "4) Sort the counties by their populations, descending order.  I started by typing arcpy.sort into the Python interface in ArcGIS, and was able to select the right tool based on my expectations.  I don't remember this part of the code giving me any trouble, though  I'm not sure how long this one took me because I also went back and decompressed all the older pieces of code by adding definitions and notes to the reader.  Until this, the entire code was about 6 or 7 lines long total.  I think I worked about an hour and a half on getting everything just the way I wanted it, as well as writing this part of the code"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##Sort the counties by their populations, descending, in a new table\n",
      "\n",
      "#Import environments\n",
      "import arcpy\n",
      "from arcpy import env\n",
      "arcpy.env.workspace = \"C:\\\\Users\\\\Valenter\\\\Documents\\\\GitHub\\\\Lab1\\\\outputs\"\n",
      "\n",
      "#Define input\n",
      "in_dataset = top10\n",
      "#Define output file\n",
      "out_dataset = \"C:\\\\Users\\\\Valenter\\\\Documents\\\\ArcGIS\\\\Default.gdb\\\\top10sort\"\n",
      "#Define which column to sort by, and in what order\n",
      "sort_field = [[\"SUM_POP2013\", \"DESCENDING\"]]\n",
      "\n",
      "#Execute the sort\n",
      "arcpy.Sort_management(in_dataset, out_dataset, sort_field)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "5) Print the top ten county populations based on the pre-sorted table. I read most of the code out of the book, but struggled at getting only the top ten to print for quite a while.  I tried to use where loops (i = 0...i +=1) and for loops (for OBJECTID* <= 10), and a good amount of other nonsense I can't quite remember.  I might have worked through a whole bunch of this nonsense for over 45 minutes.  I took a break, came back, noticed the where_clause, and had my code finished with comments, variables, and all within 10 minutes after my break.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##Print top 10 counties by population based on the pre-sorted table from step 4\n",
      "\n",
      "#import environments\n",
      "import arcpy\n",
      "from arcpy import env\n",
      "arcpy.env.workspace = \"C:\\\\Users\\\\Valenter\\\\Documents\\\\GitHub\\\\Lab1\\\\outputs\"\n",
      "\n",
      "#Define table containing pre-sorted populations\n",
      "in_table = \"top10_sortf\"\n",
      "#Define field names to be listed\n",
      "field_names = \"SUM_POP2013\"\n",
      "#Define paramater where only the first ten are printed\n",
      "where = '\"OBJECTID*\" <= 10'\n",
      "\n",
      "#Define cursor span using the variables above\n",
      "cursor = \"arcpy.da.SearchCursor(in_table, field_names, where)\"\n",
      "\n",
      "#Execute the print\n",
      "for row in cursor:\n",
      "     print \"{0}\".format(row[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}